# IP和域名裂变工具
# 版本: 1.0
# 日期: 2024-01-14
# 作者: CLAUDE

# ================ 导入所需库 ================
# 标准库导入
import os                      # 操作系统接口
import re                      # 正则表达式
import random                  # 随机数生成
import ipaddress              # IP地址处理
import subprocess             # 子进程管理
import concurrent.futures     # 并发执行

# 第三方库导入
import requests               # HTTP请求
from lxml import etree        # XML和HTML解析
from fake_useragent import UserAgent  # 随机User-Agent生成
from requests.adapters import HTTPAdapter  # HTTP适配器
from urllib3.util.retry import Retry      # 重试机制

# ================ 配置部分 ================
# 文件配置
ips = "Fission_ip.txt"         # IP地址文件
domains = "Fission_domain.txt"  # 域名文件
dns_result = "dns_result.txt"   # DNS查询结果文件

# 并发配置
max_workers_request = 20   # 并发请求数量
max_workers_dns = 50       # 并发DNS查询数量

# 生成随机User-Agent
ua = UserAgent()

# 网站配置 - 用于IP反查域名的网站列表
sites_config = {
    "site_ip138": {
        "url": "https://site.ip138.com/",
        "xpath": '//ul[@id="list"]/li/a'
    },
    "dnsdblookup": {
        "url": "https://dnsdblookup.com/",
        "xpath": '//ul[@id="list"]/li/a'
    },
    "ipchaxun": {
        "url": "https://ipchaxun.com/",
        "xpath": '//div[@id="J_domain"]/p/a'
    }
}

# ================ 功能函数 ================
# 设置HTTP会话
def setup_session():
    """
    创建并配置HTTP会话，包含重试机制
    """
    session = requests.Session()
    retries = Retry(total=5, backoff_factor=0.3, status_forcelist=[500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retries)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# 生成请求头
def get_headers():
    """
    生成随机的HTTP请求头
    """
    return {
        'User-Agent': ua.random,
        'Accept': '*/*',
        'Connection': 'keep-alive',
    }

# IP反查域名函数
def fetch_domains_for_ip(ip_address, session, attempts=0, used_sites=None):
    """
    查询指定IP地址绑定的域名，支持自动重试和切换查询网站
    
    参数:
    ip_address: 要查询的IP地址
    session: HTTP会话对象
    attempts: 当前尝试次数
    used_sites: 已使用过的查询网站列表
    """
    print(f"Fetching domains for {ip_address}...")
    if used_sites is None:
        used_sites = []
    if attempts >= 3:  # 最多尝试3次
        return []

    # 选择未使用的查询网站
    available_sites = {key: value for key, value in sites_config.items() if key not in used_sites}
    if not available_sites:
        return []  

    site_key = random.choice(list(available_sites.keys()))
    site_info = available_sites[site_key]
    used_sites.append(site_key)

    try:
        # 发送HTTP请求
        url = f"{site_info['url']}{ip_address}/"
        headers = get_headers()
        response = session.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        html_content = response.text

        # 解析HTML响应
        parser = etree.HTMLParser()
        tree = etree.fromstring(html_content, parser)
        a_elements = tree.xpath(site_info['xpath'])
        domains = [a.text for a in a_elements if a.text]

        if domains:
            print(f"succeed to fetch domains for {ip_address} from {site_info['url']}")
            return domains
        else:
            raise Exception("No domains found")

    except Exception as e:
        print(f"Error fetching domains for {ip_address} from {site_info['url']}: {e}")
        return fetch_domains_for_ip(ip_address, session, attempts + 1, used_sites)

# 并发处理IP地址
def fetch_domains_concurrently(ip_addresses):
    """
    并发处理多个IP地址的域名查询
    
    参数:
    ip_addresses: IP地址列表
    """
    session = setup_session()
    domains = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers_request) as executor:
        future_to_ip = {executor.submit(fetch_domains_for_ip, ip, session): ip for ip in ip_addresses}
        for future in concurrent.futures.as_completed(future_to_ip):
            domains.extend(future.result())

    return list(set(domains))  # 去重返回

# DNS查询函数
def dns_lookup(domain):
    """
    执行DNS查询，获取域名对应的IP地址
    
    参数:
    domain: 要查询的域名
    """
    print(f"Performing DNS lookup for {domain}...")
    result = subprocess.run(["nslookup", domain], capture_output=True, text=True)
    return domain, result.stdout

# 域名解析IP函数
def perform_dns_lookups(domain_filename, result_filename, unique_ipv4_filename):
    """
    批量执行DNS查询并处理结果
    
    参数:
    domain_filename: 域名文件
    result_filename: 结果输出文件
    unique_ipv4_filename: 唯一IPv4地址输出文件
    """
    try:
        # 读取域名列表
        with open(domain_filename, 'r') as file:
            domains = file.read().splitlines()

        # 并发执行DNS查询
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers_dns) as executor:
            results = list(executor.map(dns_lookup, domains))

        # 保存查询结果
        with open(result_filename, 'w') as output_file:
            for domain, output in results:
                output_file.write(output)

        # 提取IPv4地址
        ipv4_addresses = set()
        for _, output in results:
            ipv4_addresses.update(re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', output))

        # 读取现有IP列表
        with open(unique_ipv4_filename, 'r') as file:
            exist_list = {ip.strip() for ip in file}

        # 过滤公网IP
        filtered_ipv4_addresses = set()
        for ip in ipv4_addresses:
            try:
                ip_obj = ipaddress.ip_address(ip)
                if ip_obj.is_global:
                    filtered_ipv4_addresses.add(ip)
            except ValueError:
                continue
        
        filtered_ipv4_addresses.update(exist_list)

        # 保存过滤后的IP地址
        with open(unique_ipv4_filename, 'w') as output_file:
            for address in filtered_ipv4_addresses:
                output_file.write(address + '\n')

    except Exception as e:
        print(f"Error performing DNS lookups: {e}")

# ================ 主函数 ================
def main():
    """
    主函数，协调整个程序的执行流程
    """
    # 确保文件存在
    if not os.path.exists(ips):
        with open(ips, 'w') as file:
            file.write("")
    
    if not os.path.exists(domains):
        with open(domains, 'w') as file:
            file.write("")

    # 执行IP反查域名
    with open(ips, 'r') as ips_txt:
        ip_list = [ip.strip() for ip in ips_txt]

    domain_list = fetch_domains_concurrently(ip_list)
    print("域名列表为")
    print(domain_list)
    
    # 合并现有域名列表
    with open("Fission_domain.txt", "r") as file:
        exist_list = [domain.strip() for domain in file]

    domain_list = list(set(domain_list + exist_list))

    # 保存更新后的域名列表
    with open("Fission_domain.txt", "w") as output:
        for domain in domain_list:
            output.write(domain + "\n")
    print("IP -> 域名 已完成")

    # 执行域名解析IP
    perform_dns_lookups(domains, dns_result, ips)
    print("域名 -> IP 已完成")

# ================ 程序入口 ================
if __name__ == '__main__':
    main() 